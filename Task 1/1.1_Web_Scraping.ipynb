{"cells":[{"cell_type":"markdown","metadata":{"id":"FLNm5ld6vbvE"},"source":["# Task 1\n","\n","---\n","\n","## 1.1 Web Scraping\n","\n","This Jupyter notebook includes some code to get we started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once we've collected our data and saved it into a local `.csv` file we should start with our analysis.\n","\n","### Scraping data from Skytrax\n","\n","If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n","\n","If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qpA3fn1_vbvQ"},"outputs":[],"source":["# Importing the 'requests' library, which allows us to send HTTP requests and interact with web pages.\n","import requests\n","\n","# Importing 'BeautifulSoup' from the 'bs4' (BeautifulSoup4) library, which helps in parsing HTML and XML documents.\n","from bs4 import BeautifulSoup\n","\n","# Importing the 'pandas' library and aliasing it as 'pd'. Pandas is a powerful data manipulation and analysis library.\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SMPnVNqYvbvU"},"outputs":[],"source":["base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n","pages = 10\n","page_size = 100\n","\n","reviews = []\n","\n","# for i in range(1, pages + 1):\n","for i in range(1, pages + 1):\n","\n","    print(f\"Scraping page {i}\")\n","\n","    # Create URL to collect links from paginated data\n","    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n","\n","    # Collect HTML data from this page\n","    response = requests.get(url)\n","\n","    # Parse content\n","    content = response.content\n","    parsed_content = BeautifulSoup(content, 'html.parser')\n","    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n","        reviews.append(para.get_text())\n","\n","    print(f\"   ---> {len(reviews)} total reviews\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ew_kahyEvbvY"},"outputs":[],"source":["df = pd.DataFrame()\n","df[\"reviews\"] = reviews\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z4K1AXlhvbvZ"},"outputs":[],"source":["# This line of code exports the DataFrame 'df' to a CSV (Comma-Separated Values) file.\n","df.to_csv(\"BritishAirwaysReviews.csv\")"]},{"cell_type":"markdown","metadata":{"id":"VeZ63VV4vbva"},"source":["⚠️**Attention:** The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"niSTMYOavbvb"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}